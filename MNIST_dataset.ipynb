{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# prompt: import TensorFlow and give me its version\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.__version__\n"
      ],
      "metadata": {
        "id": "fFu132GH73He",
        "outputId": "b66b4b60-9591-4b92-ce48-db5ffd9244f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.15.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: use the mnist dataset of handwritten numbers in keras\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "\n",
        "from keras.layers import Conv2D, MaxPooling2D\n"
      ],
      "metadata": {
        "id": "Iu_2Lt2Y8mRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: assign the mnist dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
      ],
      "metadata": {
        "id": "bD39L-fg8mVK",
        "outputId": "5a3b78b4-9163-435f-b1a8-9ef186a0599b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print a random element in x_train using matplotlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.imshow(x_train[6])\n",
        "# plt.show()\n",
        "print(x_train[6])\n",
        "\n"
      ],
      "metadata": {
        "id": "BGKjnexM8mX0",
        "outputId": "2e24a1e4-9086-44ef-fb32-478871059f30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0 145 255 211  31   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  32 237 253 252  71   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11 175 253 252  71   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0 144 253 252  71   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  16 191 253 252  71   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  26 221 253 252 124  31   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0 125 253 252 252 108   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 253 252 252 108   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 255 253 253 108   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 253 252 252 108   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 253 252 252 108   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 253 252 252 108   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 255 253 253 170   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 253 252 252 252  42\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 149 252 252 252 144\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 109 252 252 252 144\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 218 253 253 255\n",
            "   35   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 175 252 252 253\n",
            "   35   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  73 252 252 253\n",
            "   35   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  31 211 252 253\n",
            "   35   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: normalize the mnist dataset\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n"
      ],
      "metadata": {
        "id": "56ubtd7X8mam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print a random element in x_train using matplotlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.imshow(x_train[6])\n",
        "# plt.show()\n",
        "print(x_train[6])\n",
        "\n"
      ],
      "metadata": {
        "id": "4jjeVInP8mdv",
        "outputId": "b8009d95-0409-4357-afe9-ed62d765568b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.5686275  1.         0.827451   0.12156863 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.1254902\n",
            "  0.92941177 0.99215686 0.9882353  0.2784314  0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.04313726\n",
            "  0.6862745  0.99215686 0.9882353  0.2784314  0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.5647059  0.99215686 0.9882353  0.2784314  0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.0627451\n",
            "  0.7490196  0.99215686 0.9882353  0.2784314  0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.10196079\n",
            "  0.8666667  0.99215686 0.9882353  0.4862745  0.12156863 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.49019608 0.99215686 0.9882353  0.9882353  0.42352942 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.99215686 0.9882353  0.9882353  0.42352942 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         1.         0.99215686 0.99215686 0.42352942 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.99215686 0.9882353  0.9882353  0.42352942 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.99215686 0.9882353  0.9882353  0.42352942 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.99215686 0.9882353  0.9882353  0.42352942 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         1.         0.99215686 0.99215686 0.6666667  0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.99215686 0.9882353  0.9882353  0.9882353  0.16470589\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.58431375 0.9882353  0.9882353  0.9882353  0.5647059\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.42745098 0.9882353  0.9882353  0.9882353  0.5647059\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.85490197 0.99215686 0.99215686 1.\n",
            "  0.13725491 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.6862745  0.9882353  0.9882353  0.99215686\n",
            "  0.13725491 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.28627452 0.9882353  0.9882353  0.99215686\n",
            "  0.13725491 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.12156863 0.827451   0.9882353  0.99215686\n",
            "  0.13725491 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: now for that dataset create a neural network sequential model from keras\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "1V15QMYy8mh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: fit the model to that dataset\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5)\n"
      ],
      "metadata": {
        "id": "xR-GQn6O8mmF",
        "outputId": "556bf173-066c-4e10-b1e8-431207e9cb44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 60s 31ms/step - loss: 0.2061 - accuracy: 0.9374\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 57s 30ms/step - loss: 0.0758 - accuracy: 0.9776\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 56s 30ms/step - loss: 0.0575 - accuracy: 0.9836\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 56s 30ms/step - loss: 0.0449 - accuracy: 0.9862\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 56s 30ms/step - loss: 0.0376 - accuracy: 0.9886\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b41daa4c340>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: evaluate the model and print the evaluation scores\n",
        "\n",
        "model.evaluate(x_test, y_test)\n"
      ],
      "metadata": {
        "id": "xaBdhkqDFX6A",
        "outputId": "8be4197c-b3f9-4d02-d144-11452d570f57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0261 - accuracy: 0.9909\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.026088235899806023, 0.9908999800682068]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: save the model as rare\n",
        "\n",
        "model.save('rare.h5')\n"
      ],
      "metadata": {
        "id": "V2WloxYNFwPM",
        "outputId": "4c6db665-adc0-4113-e618-3ae6b6e9e0bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: load the model\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "model1 = load_model('rare.h5')\n"
      ],
      "metadata": {
        "id": "kQMcl72_FwS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: predict a random number in test dataset using the loaded model\n",
        "\n",
        "predictions = model.predict(x_test)\n",
        "print(predictions[6])\n"
      ],
      "metadata": {
        "id": "1piLE7WoFwXC",
        "outputId": "bd345115-916f-4c05-a38c-d8835548bb1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.2849509e-11, 2.0789091e-08, 2.1063297e-06, 7.6747128e-08,\n",
              "        3.5956525e-08, 7.5279817e-11, 2.9977697e-13, 9.9999774e-01,\n",
              "        8.0792456e-10, 1.6052008e-08]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: get the output of the model for that prediction\n",
        "import numpy as np\n",
        "\n",
        "print(np.argmax(predictions[6]))\n"
      ],
      "metadata": {
        "id": "cxsOLBQjFwbu",
        "outputId": "c7ca0955-1e53-434f-ba10-032e21bf076a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rsUrPrLIWV2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(x_test[6])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GtBEi2qOFwhQ",
        "outputId": "dd540294-4c54-4a88-9997-20fdcdcd2328",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create a chatbot using openai\n",
        "# !pip install openai PyPDF2\n",
        "!pip install openai==0.28\n",
        "import openai\n",
        "!openai migrate\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "def main():\n",
        "    while True:\n",
        "        user_input = input(\"What do you want to ask? \")\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"text-davinci-002\",\n",
        "            prompt=user_input,\n",
        "\n",
        "            temperature=0.7,\n",
        "\n",
        "        )\n",
        "        print(response[\"choices\"][0][\"text\"])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "1VebxSJPIVJk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        },
        "outputId": "4e70feb2-ec72-4c19-8e85-3050439ac689"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hiRequirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "usage: openai [-h] [-V] [-v] [-b API_BASE] [-k API_KEY] [-p PROXY [PROXY ...]] [-o ORGANIZATION]\n",
            "              {api,tools,wandb} ...\n",
            "openai: error: argument {api,tools,wandb}: invalid choice: 'migrate' (choose from 'api', 'tools', 'wandb')\n",
            "What do you want to ask? hi\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c4ec343ade7e>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-c4ec343ade7e>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What do you want to ask? \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         response = openai.ChatCompletion.create(\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-davinci-002\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         )\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             return (\n\u001b[0;32m--> 700\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    701\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    766\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             )\n",
            "\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface.\n",
        "\n",
        "!openai migrate\n"
      ],
      "metadata": {
        "id": "_h76uCA4AGRc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}